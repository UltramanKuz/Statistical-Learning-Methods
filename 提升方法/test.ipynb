{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creating a boosting tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:46<00:00,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n",
      "The accuracy is: 0.94\n",
      "Time span: 55.984665632247925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "# 使用AdaBoost算法处理二分类问题，基函数选择二叉决策树桩（单层决策树), 返回实现二分类问题的提升树.\n",
    "# 关于二叉决策树桩： \n",
    "# 总共有n个特征，n=784\n",
    "# 特征取值为2，每个特征有三种划分方式，划分点为[-0.5, 0.5, 1.5]\n",
    "# 划分规则有两种，划分点左边为正例还是右边为正例\n",
    "# 故基函数一共有n * 3 * 2种\n",
    "# 最终选择误分率最低的决策树桩\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    加载Mnist数据集\n",
    "    return: data: 图片数据, label: 标签\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    with open(file_name) as f:\n",
    "        flag = 0\n",
    "        for line in f:\n",
    "            line = line.strip().split(',')\n",
    "            # 减少特征数量，否则运行时间太长\n",
    "            data.append([int(int(i) >= 128) for i in line[1:]])\n",
    "            # 二分类问题，只判断是否为0类\n",
    "            label.append(1 if int(line[0]) == 0 else -1)\n",
    "    return data, label\n",
    "\n",
    "def classify_method(rule):\n",
    "    \"\"\"\n",
    "    根据分类规则返回L和R的值\n",
    "    \"\"\"\n",
    "    if rule == 'L1':\n",
    "        # 左节点为正例\n",
    "        L = 1\n",
    "        R = -1\n",
    "    else: \n",
    "        # 右节点为正例\n",
    "        L = -1\n",
    "        R = 1\n",
    "    return L, R\n",
    "\n",
    "def calculate_e(train_data, train_label, feature, division_point, rule, weight):\n",
    "    \"\"\"\n",
    "    计算单个决策树桩的误分率\n",
    "    \"\"\"\n",
    "    e = 0\n",
    "    # 只需要当前特征的数据\n",
    "    feature_col = train_data[:, feature]\n",
    "    # 确定分类规则\n",
    "    L, R = classify_method(rule)\n",
    "    for i in range(len(train_data)):\n",
    "        if feature_col[i] < division_point:\n",
    "            if train_label[i] != L:\n",
    "                # 误分类时，误分类率要加上该样本的权重\n",
    "                e += weight[i]\n",
    "        else:\n",
    "            if train_label[i] != R:\n",
    "                e += weight[i]\n",
    "    return e\n",
    "\n",
    "def get_error_index(train_data, train_label, tree):\n",
    "    \"\"\"\n",
    "    计算误分类的样本索引，用于更新权重\n",
    "    \"\"\"\n",
    "    feature = tree['feature']\n",
    "    division_point = tree['division_point']\n",
    "    rule = tree['rule']\n",
    "    error_index = []\n",
    "    feature_col = train_data[:, feature]\n",
    "    L, R = classify_method(rule)\n",
    "    for i in range(len(train_data)):\n",
    "        if feature_col[i] < division_point:\n",
    "            if train_label[i] != L:\n",
    "                error_index.append(i)\n",
    "        else:\n",
    "            if train_label[i] != R:\n",
    "                error_index.append(i)\n",
    "    return error_index\n",
    "\n",
    "\n",
    "def update_weight(weight, alpha, error_index):\n",
    "    \"\"\"\n",
    "    更新样本权重\n",
    "    \"\"\"\n",
    "    for i in range(len(weight)):\n",
    "        if i in error_index:\n",
    "            weight[i] *= math.exp(alpha)\n",
    "        else:\n",
    "            weight[i] *= math.exp(-alpha)\n",
    "    # 归一化，使其表示权重\n",
    "    return np.array(weight) / sum(weight)\n",
    "\n",
    "def create_single_boosting_tree(train_data, train_label, weight):\n",
    "    \"\"\"\n",
    "    创建单棵提升树\n",
    "    \"\"\"\n",
    "    tree = {}\n",
    "    feature_num = train_data.shape[1]\n",
    "    e = 1\n",
    "    for feature in range(feature_num):\n",
    "        for division_point in [-0.5, 0.5, 1.5]:\n",
    "            for rule in ['L1', 'R1']:\n",
    "                tmp_e = calculate_e(train_data, train_label, feature, division_point, rule, weight)\n",
    "                # 选择误分率最低的决策树桩，保存其信息\n",
    "                if tmp_e < e:\n",
    "                    e = tmp_e\n",
    "                    tree['e'] = e\n",
    "                    tree['feature'] = feature\n",
    "                    tree['division_point'] = division_point\n",
    "                    tree['rule'] = rule\n",
    "                    tree['alpha'] = 0.5 * math.log((1 - e) / e)\n",
    "    return tree\n",
    "\n",
    "def create_boosting_tree(train_data, train_label, tree_num=50):\n",
    "    \"\"\"\n",
    "    创建提升树\n",
    "    \"\"\"\n",
    "    train_data = np.array(train_data)\n",
    "    train_label = np.array(train_label)\n",
    "    m = train_data.shape[0]\n",
    "    # 初始化的权重为相等权重\n",
    "    weight = [1 / m] * m\n",
    "    boosting_tree = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(tree_num)):\n",
    "        # 创建单棵提升树\n",
    "        tree = create_single_boosting_tree(train_data, train_label, weight)\n",
    "        boosting_tree.append(tree)\n",
    "        # 更新权重\n",
    "        error_index = get_error_index(train_data, train_label, tree)\n",
    "        alpha = tree['alpha']\n",
    "        weight = update_weight(weight, alpha, error_index)\n",
    "        boosting_tree.append(tree)\n",
    "    return boosting_tree\n",
    "\n",
    "def predict(tree, x):\n",
    "    \"\"\"\n",
    "    预测单个数据的类别\n",
    "    \"\"\"\n",
    "    L, R = classify_method(tree['rule'])\n",
    "    if x[tree['feature']] < tree['division_point']:\n",
    "        return L\n",
    "    else:\n",
    "        return R\n",
    "    \n",
    "\n",
    "def test(test_data, test_label, boosting_tree):\n",
    "    \"\"\"\n",
    "    测试准确率\n",
    "    \"\"\"\n",
    "    test_data = np.array(test_data)\n",
    "    test_label = np.array(test_label)\n",
    "    m = test_data.shape[0]\n",
    "    error_cnt = 0\n",
    "    for i in range(m):\n",
    "        value = 0\n",
    "        for tree in boosting_tree:\n",
    "            value += tree['alpha'] * predict(tree, test_data[i])\n",
    "        # value 为正则为正例，反之为负例\n",
    "        if np.sign(value) != test_label[i]:\n",
    "            error_cnt += 1\n",
    "    return 1 - error_cnt / m\n",
    "\n",
    "def main():\n",
    "    # 开始时间\n",
    "    start = time.time()\n",
    "\n",
    "    # 获取训练集\n",
    "    train_data, train_label = load_data('../mnist_train.csv')\n",
    "    # 获取测试集\n",
    "    test_data, test_label = load_data('../mnist_test.csv')\n",
    "\n",
    "    # 创建提升树\n",
    "    print('Start creating a boosting tree')\n",
    "    tree = create_boosting_tree(train_data[:1000], train_label[:1000], 10)\n",
    "\n",
    "    #测试准确率\n",
    "    print('Start testing')\n",
    "    accuracy = test(test_data[:100], test_label[:100], tree)\n",
    "    print('The accuracy is:', accuracy)\n",
    "\n",
    "    #结束时间\n",
    "    end = time.time()\n",
    "    print('Time span:', end - start)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
